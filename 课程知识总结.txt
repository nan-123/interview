                                                                      课程知识总结：
																	  
																	  
                                                                    springmvc-加载过程：
配置阶段：
 web.xml 配置servlet入口
初始化阶段 ApplicationContextAware-FrameworkServlet-DispatcherServlet做策略分发 九大策略
请求处理阶段：
 DispatcherServlet doService 调用 doDispatch getHandler   根据用户请求的url可以获取到一个controller 中的 方法 
 getHandlerAdapter：根据方法的参数进行动态匹配，转型
 HandlerAdapter中getHandler 获取modeandview 
 applyDefaultViewName:结果视图对象的处理
 processDispatchResult: resolveViewName 最终返回字符串
 write() 
 -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 
 
                                                                          spring事务：
 有4个特性：原子性，一致性， 隔离性，持久性     acid
 spring事务的传播：
 PROPAGATION_REQUIRED ：spring默认的事务，如果没有就新建事务
 PROPAGATION_REQUIRES_NEW：新建事务，如果当前有，就把当前的事务挂起
 PROPAGATION_SUPPORTS：支持当前事务，如果没有，就按照非事务处理
 PROPAGATION_MANDATORY：没事务就抛出异常
 PROPAGATION_NOT_SUPPORTED：不支持事务，有事务挂起
 PROPAGATION_NEVER：不支持事务，有事务抛异常
 PROPAGATION_NESTED：嵌套事务，如果当前有，就嵌套，没有就按照REQUIRED 处理，有多个回滚点
 
 数据库隔离级别：
 Read-Uncommitted 导致读脏数据  0 ：就是一个事务可以读到另一个事务正操作但未提交的数据
 Read-Committed  不能脏读，但可以不可重复读，幻读 1
  不可重复读：就是一个事务两次查询重复数据中间有一个事务改变了数据导致两次查询的结果不一样
  幻读：一个事务在做批量修改，另一个事务在修改范围内增加了一条数据，但这条数据不会被事务1修改到 幻读的重点在于新增或者删除 (数据条数变化)
  
 Repeatable-Read 不能脏读，不可重复读，但可以幻读 2
 Serializable ：最高级别，但效率很低   3
 
  spring中的隔离级别：
 ISOLATION_DEFAULT：PlatfromTransactionManager的默认隔离级别，使用数据库的隔离级别
 ISOLATION_READ_UNCOMMITTED：可以脏读，不可重复读，幻读，最低级别
 ISOLATION_READ_COMMITTED：不可脏读
 ISOLATION_REPEATABLE_READ：不可脏读，不可不重复读
 ISOLATION_SERIALIZABLE：持久化
 
 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 
 
                                                                            spring问题收集
1：spring作用域
singleton:  默认是单例的
prototype: 原型，为每一个bean请求提供一个实例
request：每次网络请求创建一个实例，在请求完成后被回收
session：每次回话有一个实例bean，session过期失效
global-session：用于全局声明


 2：动态代理 cglib 与jdk
 
 
 
 spring循环注入
 利用递归+缓存
 
 
怎么保证bean不被回收
1： ioc容器map中，会一直持有对象的引用
 map又是单例的，map本身不会被回收
 
2： 不同数据源的事务如何处理
 在spring中，事务是不支持夸数据源的
 换句话说，一个事务是不能操作两个数据库的
 因为datasouce是connection，当创建语句集的时候才能开始事务
 
 解决：使用中间件，做一些消息同步，利用分布式锁去实现分布式事务
 
3：spring如何保证controller 并发安全
   用springboot
 -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 configuration --- sqlsession --- executor mybatis三巨头
 
 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 
 
 
                                                                         分步式基础知识：
 集群：多台业务类型一样的服务器
 分布式：业务拆分，一个业务一台服务器
 集群+分布式
 
 分布式架构难点：
1：三态 成功 失败 超时/未知
2：分布式事务 （多个存储节点下数据库一致性问题）
3：负载均衡  领域服务层负载，服务发现
4：一致性  cap 
5：故障的独立性 隔离

-------------------------------------------------------------------------------------------------------


                                                                           分布式架构设计01：
 soa：面向服务架构：是一种架构，一种设计
 微服务架构：
soa架构的升华，业务彻底的服务化和组件化
组件化：完全独立
微服务特征：
1：组件化
2：按业务能力划分服务和开发团队
3：去中心化
4：基础设施的自动化
 CAP:
    一致性， 可用性，分区容错性
	cp/ap  只能选择其一
BASE:
    基本可用（搜索由1s变成2s，降级页面（当前访问过多））
	软状态 （状态机） 待支付，支付中，交易成功，交易失败
	数据最终一致性 基于mq 重试 
	
四：分布式架构下的高可用设计（很少有不能用的时候）
   避免单点故障：
    负载均衡（failover、选址，硬件负载。软件负载，去中心化（gossip（redis-cluster）））
	热备 ha
	多机房（同城灾备，异地灾备）
  应用高可用性：
    故障监控（系统监控 cpu，内存  链路监控 日志监控）自动预警
	应用的容错设计，服务降级，限流 自我保护
	数据量（数据分片，读写分离）
  
	
五：可伸缩设计（后续怎么提升性能）
   垂直伸缩：提升硬件能力 
   水平伸缩：增加服务器
----------------------------------------------------------------------------------------------------------------------------------------------------------------------


                                                                 分布式架构基石 协议：tcp udp multicast 
io : bio NIO AIO
 Socket
 NIO(Netty/Mima)
 序列化与反序列化
 OSI 七层网络模式
 TCP/IP四层概念模型 传输层：tcp头 http请求报文 --- 网络层：ip头 tcp头 http请求报文  --- 
                    数据链路层： mac ip头 tcp头 http请求报文 --- 物理层 ：转换成 0101010
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
http&https协议
	post：创建 get：查询 delete：删除 put：更新 option:查询方法（post、get） head
----------------------------------------------------------------------------------------------------------------------------------------------------------------


                                                                        序列化与反序列化	
了解序列化的意义：
 网络传输对象 a -- 网络 -- b 
 java 本身序列化 ：serialization
  问题：
    1：数据比较大
	2：语音限制
	解决：使用xml（soap）
 发展：
  json
   数据大，性能低
  protobufs messagepack 
  
  serialiaUUid作用：可以不写，但如果改变了自动会读取不到，编译后自动生成，反序列化校验，不同报错
  静态变量的序列化：
  不参与序列化，序列化之后再去改变反序列化也是相等的
  transient 修饰不参与序列化只取默认值
  父类不实现序列化：不参与序列化
  父类实现序列化：同样参与
  父类实现子类不实现：传递给子类 相当于子类也实现了序列化
  让transient修饰也可以序列化 ： 实体类里面写一个流方法赋值给 让transient修饰的字段
   相当于手动序列化
  同一个流里面连续序列化两次：只是在原来的序列化基础加上了5个字节（引用指向，不会叠加）
  序列化克隆：
   深克隆：需要用到序列化和反序列化生成新的对象，新的引用
 --------------------------------------------------------------------------------------------------------------------------------------------------------------------
 
 
                                                                           zookeeper
 树形文件结构
  /
   /app
    /app/app1
	 http:地址1
	 http:地址2

 节点的特性：
  1：同级节点的唯一性
  2：临时节点（会话周期）和持久化节点
  3：有序节点和无序节点
  4：临时节点下不能存子节点
  
  2pc提交
 watcher:当数据发生变化，zk会产生一个watcher事件，会发送一次给客户端，但只会发生一次，如果要永久监听，需要循环监听
 
------------------------------------------------------------------------------------------------------------------------------------------------------------------


                                                                            dubbo
LB:负载均衡
服务治理：负载，容错，降级。。。。
consumer：订阅1  1通知2 2调用3
 monitor：监控
 container:发布容器
 dubbo 多协议支持：
   rmi hessian sebservice http thirft dubbo（默认）
 ：spi
   java spi
    例如 java定义规范数据库驱动规范，不同数据库厂商实现
   dubbo的spi规范
    1：/META-INF/dubbo;META-INF/internal;META-INF/
	
  源码：
   三个注解：
    @SPI 标注是一个扩展点 默认是dubbo 默认使用的extension 必须是接口上使用
	@Adaptive 适配器 
	 1：如果配置在类级别上，表示自定义适配器
	 2：如果是配置在方法级别上，表示需要动态创建
	 
	 实际很好理解，结合spi模式，定义规范，别人实现
	  @SPI 就是一个规范，默认是dubbo，如果写其他的 例如spi（"nan"）,那么就需要在/META-INF/dubbo定义一个 nan = xxxx.xxx.xx 这个就是适配器
	    加载的时候就会判断，各种处理找到这个适配器
		dubbo的主要作用--用指定协议发布服务
dubbo：20880 rmi：1099 hession：80 webserver：80  -- 默认
 
  发布过程：
   读取xml文件中个个标签的个个节点到对应的类和对应的属性上
   1：加载扩展点
   2：监听服务端
   3：注册到zookeeper
    1：通过zk客户端连接到zookeeprer
	2:订阅发布
	a:启动一个nettyserver
	b:获取注册中心。在zookeepr上注册协议地址
	
 客户端：
  获取代理
   判断是不是点对点（是否配置了url）点对点不走注册中心
-----------------------------------------------------------------------------------------------------------------------------------------------------------------


                                                                               kafka
什么是kafka
  是一款分布式消息和订阅系统，高性能，高吞吐量，scala语言
  一般用于行为跟踪，日志收集（百丽就是这个）
  elk：在系统中配置kafka，日志流方式通过kafka+zookeeper集群转换成流的方式日志记录，通过ela生成消息，最后在kibana展示
kafka架构：
  broker：消息载体：收集，发送
  topic :主题 大表
  partition：数据分区 大表里面的小表
  group：所属
  
配置参数分析：消息确认配置，消息方式-offset
 2.1.7版本
 
消息的写入性能
  按照顺序写入，不用寻址，性能高
  0拷贝  
   正常流程 磁盘--缓存--app缓存--socket流--nic流，需要经历4次复制
   kafka采用直接从页缓存直接到socket
  消息的存储机制：
   分段保存：index.long ... 000000000000.log 保存成多个文件
partition 副本概念
-----------------------------------------------------------------------------------------------------------------------------------------------------------------
                                                                                              rabbitmq
TTL:过期时间
死信队列：
延迟队列：
消息中间件作用：
异步 解耦 削峰
应用：秒杀
AMQP协议：跨语言，跨系统，rabbitmq采用了这个协议
特性：
可靠性
灵活性的路由
消息集群
高可用
多协议
多语言客户端
管理界面
插件机制
模型：
 pruducer-msg-路由key？--》交换机-绑定-queue--con--消息通道--消费者
自带虚拟机，可以做环境隔离
4种模型交换机
1：dirctExchange:直连交换机
   必须指定路由key，必须跟绑定key完全匹配才能把消息发送到队列上
2：主题交换机（TOPIC Exchange ）
   指定路由key，dinding key通过匹配符号来匹配，如果多个绑定key能匹配上会发送都多个队列
3:广播类型交换机
  不用路由key，也不需要绑定key，所有队列都能收到
 
进阶消息：
 怎么自动删除没人消费的消息
  1：设置一个队列的消息TTL
  2:对每条消息设置过期时间
  
 死信队列: Dead letter queue
  死信产生：
   1：消费者没有使用自动应答而且拒绝了消息
   2：消息过期
   3：队列达到最大长度（可配置）-前面的消息就会去到死信队列
   4：超过单条消息最大长度
  去到：x-dead-letter-exchange
  然后可以设置单独消费者处理死信消息
 3：优先级队列
  1：发送的时候指定优先级，默认：5
 4：延迟队列：半个小时后发送或者半个小时后被消费
  1：延迟队列的插件
  2：设置半个小时过去--去到死信队列--消费死信队列
 5：实现rpc：
  在不同网络或者不同语言场景
   客户端发送4--服务端返回16，就是两个指定id信道相互通讯
 6：流量控制：
   设置消息大小是没有的，x-max-length 只有消息堆积时候才有用，因为先进的被抛弃不符合场景
   正确实现：
    1：服务端： 设置内存 或者磁盘，剩余多少的时候不再工作
	2：客户端：设置prefetch.count 预取数量
面试题：
 1：消息队列的作用与使用场景：
  异步，削峰，解耦
  批量上传文件
  秒杀
  退货流程解耦
  广播：一对多
 2：多消费者监听一个消息队列
  ：轮询  公平分发
  可这是basicqos ，防止单台机器
 3：消息无法被路由会怎样：
  重发或者备份交换机
 4：消息什么情况会去到死信
  被消费者拒绝，不能重新入队；消息过期；队列发生了堆积，消息不能再去到这个队列，之前的消息会去到死信
 5：怎么设置延迟消息
  可用插件，或者利用死信队列
 6：可靠性投递
  事务，路由，存储，消费者确认，或者配合业务（数据入库状态判断是否重发）
 7：消息冥等
  生产者对每条数据加上唯一id（其实就是通过数据字段）
 8：流量控制
  内存，磁盘设置，消费端用prefetch count控制
 9：顺序性
  全局id，从小到大自增，前一条没出来就不处理下一条
 10：rabbitmq集群：
  普通模式，镜像模式
  磁盘节点-内存节点
  
  ------------------------------------------------------------------------------------------------------------------------------------------------------------
                                                                                             mangodb
 
 1：mangodb的应用场景及设计原理
   分布式文件存储的数据库，c++编写，非关系数据库
  应用场景：
   适合：
    网站实时数据 例如：日志，时间轴，用户行为
	缓存：缓存的数据一定是临时的（在关系型数据库有持久化）
	大尺寸，低价值数据存储：图片，视频
	高伸缩性场景：高可以，机器可以任意增减
	对象或者json数据的存储，用redis更好
  不适合：
   高度事务：金融系统
   结构化查询高数据
   需要复杂sql查询
新建数据库：use xxx(库名)
 删除： drop()
 查询语句：
  db.userInfo.find();--相当于：select* from userInfo;
  db.userInfo.find({“age”: 22}); 相当于： select * from userInfo where age = 22;
  db.userInfo.find({age: {$gt: 22}}); 相当于：select * from userInfo where age >22;
  db.userInfo.find({name: /mongo/});//相当于%%
  db.userInfo.find({}, {name: 1, age: 1});相当于：select name, age from userInfo;
 修改：
  db.users.update({age: 25}, {$set: {name: ‘changeName’}}, false, true);
  相当于：update users set name = ‘changeName’ where age = 25;
 删除：
  db.users.remove({age: 132});
 ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                                                                                二叉树：
 左小右大
 缺点：有可能变成瘸子树，在已存在的节点中插入数据全部比节点小或者大就会出现，性能大打折扣
 为了解决这种不平衡的问题，产生了红黑树，也叫平衡二叉树
红黑树：
 1：节点是红或者黑，根节点是黑 每个叶子节点都是黑色的空节点（NIL节点）。一红带2黑 任一节点到叶子黑色数量一样
 变色：为了符合上面规则，引发节点和叶子的颜色改变
 左旋转
 
 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------
 
 
 
                                                                                 百丽系统：
是数据的入口，包括店铺，订单，库存，商品，发货，售后数据，同时也是跟第三方平台所有的交互
是数据的处理，保存成统一内部格式，兼容各个平台然后做下发，通过消息中间件给到其他系统，订单系统，商品系统等，还接受下游系统的回传数据，例如发货数据再回传到第三方平台
除了这些，还负责数据的监控，预警邮件，例如库存熔断，发货失败的通知
本质是一个调度系统，上面的功能都是用调度的方式完成，也提供数据的页面查询功能

--------------------------------------------------------------------------------------
qps:每秒查询数，也就是最大吞吐能力,外部平台接口qps一般是50，百丽单台qps大约为1600
tps：每秒处理的事务数目
     TPS 的过程包括：客户端请求服务端、服务端内部处理、服务端返回客户端
	 一个页面就会产生一个 “T”，产生三个 “Q”
pv：页面浏览量
UV：访问数（Unique Visitor）指独立访客访问数，统计 1 天内访问某站点的用户数 (以 cookie 为依据)，一台电脑终端为一个访客。
IP：独立 IP 数，是指 1 天内多少个独立的 IP 浏览了页面
GMV：只要是订单，不管消费者是否付款、卖家是否发货、是否退货，都可放进 GMV 。
RPS：代表吞吐率 有人把 RPS 说等效于 QPS

面对超高的并发，首先硬件层面机器要能扛得住，其次架构设计做好微服务的拆分，
代码层面各种缓存、削峰、解耦等等问题要处理好，数据库层面做好读写分离、分库分表，
稳定性方面要保证有监控，熔断限流降级该有的必须要有，发生问题能及时发现处理。
这样从整个系统设计方面就会有一个初步的概念。
RPC-Dubbo-Dubbo负载均衡策略-集群容错
消息队列-消息可靠性-生产者丢失-MQ丢失-消费者丢失-消息的最终一致性
RocketMQ默认是需要消费者回复ack确认，而kafka需要手动开启配置关闭自动offset。
消费方不返回ack确认，重发的机制根据MQ类型的不同发送时间间隔、次数都不尽相同，如果重试超过次数之后会进入死信队列，需要手工来处理了。（Kafka没有这些）
数据库-水平分表-分表后的ID唯一性-设定步长-分布式ID-不用id，使用业务数据，例如订单id
 -主从同步原理
 master提交完事务后，写入binlogslave连接到master
 获取binlogmaster创建dump线程，推送binglog到slaveslave启动一个IO线程读取同步过来的master的binlog，
 记录到relay log中继日志中slave再开启一个sql线程读取relay log事件并在slave执行，完成同步slave记录自己的binglog
缓存-热key问题-缓存击穿（过期）-缓存穿透（没有的key，布隆解决）-缓存雪崩（同时过期）
稳定性-熔断-限流-降级-预案-核对





